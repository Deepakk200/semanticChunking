{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\nagir\\Downloads\\The Doctor-Approved Cannabis Handbook_DRC.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book is for informational purposes only. It is not intended to serve as a substitute for \n",
      "professional medical advice. The author and publisher specifically disclaim any and all \n",
      "liability arising directly or indirectly from the use of any information contained in this book. \n",
      "A healthcare professional should be consulted regarding your specific medical situation. Any \n",
      "product mentioned in this book does not imply endorsement of that product by the author or \n",
      "publisher.\n",
      "In certain instances, names and identifying details have been changed to protect an \n",
      "individual’s privacy.\n",
      "The Doctor-Approved Cannabis Handbook  copyright © 2023 by Benjamin Caplan\n",
      "All rights reserved. No part of this book may be used or reproduced in any manner \n",
      "whatsoever without written permission of the publisher, except in the case of brief quotations \n",
      "embodied in critical articles or reviews.\n",
      "BenBella Books, Inc.  \n",
      "10440 N. Central Expressway \n",
      "Suite 800 \n",
      "Dallas, TX 75231 \n",
      "benbellabooks.com\n",
      "\n",
      "Send feedback to feedback@benbellabooks.com\n",
      "BenBella is a federally registered trademark.\n",
      "Printed in the United States of America \n",
      "10 9 8 7 6 5 4 3 2 1\n",
      "L\n",
      "ibrary of Congress Control Number: 2023015031 \n",
      "ISBN 9781637742679 (trade paperback)  \n",
      "ISBN 9781637742686 (electronic)\n",
      "Editing by Scott Calamar \n",
      "Copyediting by Michael Fedison \n",
      "Proofreading by Sarah Vostok and Marissa Wold Uhrina \n",
      "Indexing by WordCo. \n",
      "Text design and composition by PerfecType, Nashville, TN \n",
      "Cover design by Brigid Pearson  \n",
      "Printed by Lake Book Manufacturing\n",
      "Special discounts for bulk sales are available. Please contact bulkorders@benbellabooks.com.\n",
      "\n",
      "This book is dedicated to my parents, Brenda and Lou, the greatest healthcare duo \n",
      "I know. For eight decades, they have tirelessly cared for others with compassion and \n",
      "love, and have inspired me to do the same. This book is written with endless gratitude \n",
      "for your unwavering commitment to making a positive impact in the world.\n",
      "\n",
      "Contents\n",
      "Introduction xi\n",
      "PART I  \n",
      "A Guided Cannabis Overview\n",
      "Chapter 1 The C annabis Plant 3\n",
      "Ch\n",
      "apter 2 Ho\n",
      "w Cannabis Works 32\n",
      "Ch\n",
      "apter 3 The S\n",
      "hopper’s Guide to Cannabis Products 49\n",
      "C\n",
      "hapter 4 Do\n",
      "-It-Yourself Products, Edibles, and Topicals 83\n",
      "Ch\n",
      "apter 5 St\n",
      "arting Your Guided Cannabis Journey 97\n",
      "PART II  \n",
      "Clinical Uses\n",
      "Chapter 6 Me ntal Health Issues 119\n",
      "C\n",
      "hapter 7 Sl\n",
      "eep Disturbances 133\n",
      "C\n",
      "hapter 8 He\n",
      "adaches 148\n",
      "C\n",
      "hapter 9 \n",
      " Ne\n",
      "urodegenerative Diseases: Dementia, Alzheimer’s,  \n",
      "and Parkinson’s 158\n",
      "C\n",
      "hapter 10 Se\n",
      "izures 172\n",
      "C\n",
      "hapter 11 Ph\n",
      "ysical Pain 18\n",
      "1\n",
      "\n",
      "Chapter 12 Ga strological Issues 201\n",
      "C\n",
      "hapter 13 Sk\n",
      "in Conditions 216\n",
      "C\n",
      "hapter 14 Se\n",
      "xual Function and Sexual Health 228\n",
      "C\n",
      "hapter 15 \n",
      " Tr\n",
      "eating Cancer and the Symptoms of Traditional  \n",
      "Cancer Therapies 242\n",
      "C\n",
      "hapter 16 Cr\n",
      "eating an End-of-Life Plan 257\n",
      "A\n",
      "fterword: Achieving the Best of Health and Happiness 265\n",
      "Re\n",
      "commended Reading 267\n",
      "A\n",
      "cknowledgments 269\n",
      "N\n",
      "otes 27\n",
      "1\n",
      "Index 285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_chunks = text_splitter.split_documents(documents)\n",
    "for chunk in naive_chunks[10:15]:\n",
    "  print(chunk.page_content+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagir\\AppData\\Local\\Temp\\ipykernel_8884\\2303525857.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
      "c:\\Users\\nagir\\anaconda3\\envs\\chunking\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "semantic_chunker = SemanticChunker(embed_model, breakpoint_threshold_type=\"percentile\")\n",
    "semantic_chunks = semantic_chunker.create_documents([d.page_content for d in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for semantic_chunk in semantic_chunks:\n",
    "  if \"Effect of Pre-training Tasks\" in semantic_chunk.page_content:\n",
    "    print(semantic_chunk.page_content)\n",
    "    print(len(semantic_chunk.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " JSON saved to semantic_chunks_output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_objects = []\n",
    "\n",
    "# Loop through semantic chunks and create JSON objects\n",
    "for i, semantic_chunk in enumerate(semantic_chunks):\n",
    "    idea_text = semantic_chunk.page_content.strip()\n",
    "\n",
    "    json_obj = {\n",
    "        \"ideaText\": idea_text,\n",
    "        \"references\": [\n",
    "            {\n",
    "                \"doi\": f\"doi{i+1}\",  \n",
    "                \"refRelationship\": \"optionX\"  \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    json_objects.append(json_obj)\n",
    "\n",
    "output_file_path = \"semantic_chunks_output.json\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_objects, f, indent=3, ensure_ascii=False)\n",
    "\n",
    "print(f\" JSON saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
